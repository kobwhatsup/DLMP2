# Logstash配置文件
# DLMP日志处理管道配置

# 输入配置
input {
  # Filebeat输入
  beats {
    port => 5044
    host => "0.0.0.0"
  }
  
  # Syslog输入
  syslog {
    port => 5514
    host => "0.0.0.0"
  }
  
  # TCP输入 (用于应用直接发送日志)
  tcp {
    port => 5000
    codec => json_lines
    tags => ["tcp-input"]
  }
  
  # HTTP输入
  http {
    port => 8080
    host => "0.0.0.0"
    codec => json
    tags => ["http-input"]
  }
  
  # Kafka输入 (如果使用Kafka)
  kafka {
    bootstrap_servers => "kafka:9092"
    topics => ["dlmp-logs", "dlmp-metrics", "dlmp-events"]
    group_id => "logstash-dlmp"
    consumer_threads => 3
    codec => json
    tags => ["kafka-input"]
  }
  
  # Redis输入 (用于日志队列)
  redis {
    host => "redis-node-1"
    port => 6379
    password => "redis123456"
    data_type => "list"
    key => "dlmp:logs"
    codec => json
    tags => ["redis-input"]
  }
}

# 过滤器配置
filter {
  # 通用字段处理
  if [fields][service] {
    mutate {
      add_field => { "service" => "%{[fields][service]}" }
    }
  }
  
  if [fields][environment] {
    mutate {
      add_field => { "environment" => "%{[fields][environment]}" }
    }
  }
  
  # Docker容器日志处理
  if [container][name] {
    mutate {
      add_field => { "container_name" => "%{[container][name]}" }
      add_field => { "container_id" => "%{[container][id]}" }
    }
  }
  
  # Nginx访问日志处理
  if [service] == "nginx" and [log][file][path] =~ /access\.log/ {
    grok {
      match => { 
        "message" => "%{IPORHOST:remote_addr} - %{DATA:remote_user} \[%{HTTPDATE:time_local}\] \"%{WORD:method} %{DATA:request} HTTP/%{NUMBER:http_version}\" %{NUMBER:status} %{NUMBER:body_bytes_sent} \"%{DATA:http_referer}\" \"%{DATA:http_user_agent}\" \"%{DATA:http_x_forwarded_for}\" %{NUMBER:request_time} %{NUMBER:upstream_response_time}"
      }
    }
    
    mutate {
      convert => { 
        "status" => "integer"
        "body_bytes_sent" => "integer"
        "request_time" => "float"
        "upstream_response_time" => "float"
      }
    }
    
    date {
      match => [ "time_local", "dd/MMM/yyyy:HH:mm:ss Z" ]
    }
    
    # 地理位置信息
    geoip {
      source => "remote_addr"
      target => "geoip"
    }
    
    # User Agent解析
    useragent {
      source => "http_user_agent"
      target => "ua"
    }
    
    # 添加标签
    mutate {
      add_tag => ["nginx", "access-log"]
    }
  }
  
  # Nginx错误日志处理
  if [service] == "nginx" and [log][file][path] =~ /error\.log/ {
    grok {
      match => { 
        "message" => "%{DATESTAMP:timestamp} \[%{DATA:log_level}\] %{NUMBER:pid}#%{NUMBER:tid}: (\*%{NUMBER:connection_id} )?%{GREEDYDATA:error_message}"
      }
    }
    
    date {
      match => [ "timestamp", "yyyy/MM/dd HH:mm:ss" ]
    }
    
    mutate {
      add_tag => ["nginx", "error-log"]
    }
  }
  
  # Java应用日志处理
  if [service] == "dlmp-backend" {
    # 多行日志合并
    multiline {
      pattern => "^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}"
      negate => true
      what => "previous"
    }
    
    # 解析应用日志格式
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{DATA:thread}\] %{LOGLEVEL:level} %{DATA:logger} - %{GREEDYDATA:log_message}"
      }
    }
    
    date {
      match => [ "timestamp", "yyyy-MM-dd HH:mm:ss.SSS" ]
    }
    
    # 提取异常信息
    if [log_message] =~ /Exception|Error/ {
      mutate {
        add_tag => ["exception", "error"]
      }
      
      # 提取异常类型
      grok {
        match => { 
          "log_message" => "(?<exception_type>\w+Exception|Error): %{GREEDYDATA:exception_message}"
        }
        tag_on_failure => []
      }
    }
    
    # 提取性能指标
    if [log_message] =~ /执行时间|响应时间|耗时/ {
      grok {
        match => { 
          "log_message" => ".*(?<operation>\w+).*(?<execution_time>\d+(?:\.\d+)?)ms"
        }
        tag_on_failure => []
      }
      
      if [execution_time] {
        mutate {
          convert => { "execution_time" => "float" }
          add_tag => ["performance"]
        }
      }
    }
    
    # SQL日志处理
    if [logger] =~ /org\.hibernate\.SQL|com\.dlmp\.repository/ {
      mutate {
        add_tag => ["sql", "database"]
      }
    }
    
    mutate {
      add_tag => ["java", "application"]
    }
  }
  
  # MySQL日志处理
  if [service] == "mysql" {
    # 慢查询日志
    if [log][file][path] =~ /slow\.log/ {
      multiline {
        pattern => "^# Time:"
        negate => false
        what => "previous"
      }
      
      grok {
        match => { 
          "message" => "# Time: %{TIMESTAMP_ISO8601:timestamp}\n# User@Host: %{DATA:user}\[%{DATA:database}\] @ %{DATA:host} \[%{IP:ip}\]\n# Query_time: %{NUMBER:query_time} Lock_time: %{NUMBER:lock_time} Rows_sent: %{NUMBER:rows_sent} Rows_examined: %{NUMBER:rows_examined}\n%{GREEDYDATA:sql_query}"
        }
      }
      
      mutate {
        convert => { 
          "query_time" => "float"
          "lock_time" => "float"
          "rows_sent" => "integer"
          "rows_examined" => "integer"
        }
        add_tag => ["mysql", "slow-query"]
      }
    }
    
    # 错误日志
    if [log][file][path] =~ /error\.log/ {
      grok {
        match => { 
          "message" => "%{TIMESTAMP_ISO8601:timestamp} %{NUMBER:thread_id} \[%{WORD:log_level}\] %{GREEDYDATA:error_message}"
        }
      }
      
      mutate {
        add_tag => ["mysql", "error-log"]
      }
    }
  }
  
  # Redis日志处理
  if [service] == "redis" {
    grok {
      match => { 
        "message" => "%{NUMBER:pid}:%{WORD:role} %{TIMESTAMP_ISO8601:timestamp} %{WORD:log_level} %{GREEDYDATA:redis_message}"
      }
    }
    
    mutate {
      add_tag => ["redis"]
    }
  }
  
  # 安全日志处理
  if [log_message] =~ /login|authentication|authorization|failed|denied/ {
    mutate {
      add_tag => ["security"]
    }
    
    # 提取IP地址
    grok {
      match => { 
        "log_message" => ".*(?<source_ip>\d+\.\d+\.\d+\.\d+).*"
      }
      tag_on_failure => []
    }
    
    if [source_ip] {
      geoip {
        source => "source_ip"
        target => "source_geoip"
      }
    }
  }
  
  # 业务日志处理
  if [logger] =~ /com\.dlmp\.business/ {
    mutate {
      add_tag => ["business"]
    }
    
    # 提取业务操作
    grok {
      match => { 
        "log_message" => "(?<business_action>\w+) (?<business_entity>\w+) (?<entity_id>\d+)"
      }
      tag_on_failure => []
    }
  }
  
  # 通用字段清理
  mutate {
    remove_field => [ 
      "[host][name]", 
      "[agent][hostname]", 
      "[agent][name]", 
      "[agent][id]",
      "[ecs][version]",
      "[fields]"
    ]
  }
  
  # 添加处理时间戳
  ruby {
    code => "event.set('[@metadata][processed_at]', Time.now.utc.iso8601)"
  }
}

# 输出配置
output {
  # 调试输出 (开发环境)
  if [environment] == "development" {
    stdout { 
      codec => rubydebug { metadata => true }
    }
  }
  
  # Elasticsearch输出
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    
    # 根据服务和日志类型创建不同的索引
    index => "%{service}-%{+YYYY.MM.dd}"
    
    # 索引模板
    template_name => "dlmp-logs"
    template => "/usr/share/logstash/templates/dlmp-template.json"
    template_overwrite => true
    
    # 文档类型
    document_type => "_doc"
    
    # 批量设置
    flush_size => 1000
    idle_flush_time => 5
    
    # 错误处理
    action => "index"
    
    # 如果Elasticsearch不可用，将日志写入死信队列
    manage_template => true
  }
  
  # 错误日志单独索引
  if "error" in [tags] or "exception" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "dlmp-errors-%{+YYYY.MM.dd}"
    }
  }
  
  # 安全日志单独索引
  if "security" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "dlmp-security-%{+YYYY.MM.dd}"
    }
  }
  
  # 性能日志输出到InfluxDB
  if "performance" in [tags] and [execution_time] {
    influxdb {
      host => "influxdb"
      port => 8086
      measurement => "performance_metrics"
      send_as_tags => ["service", "operation"]
      data_points => {
        "execution_time" => "%{execution_time}"
      }
    }
  }
  
  # 告警输出
  if [level] == "ERROR" or [level] == "FATAL" {
    http {
      url => "http://alertmanager:9093/api/v1/alerts"
      http_method => "post"
      content_type => "application/json"
      format => "json"
      mapping => {
        "receiver" => "logstash"
        "status" => "firing"
        "alerts" => [
          {
            "labels" => {
              "alertname" => "LogstashAlert"
              "service" => "%{service}"
              "severity" => "warning"
              "instance" => "%{[host][name]}"
            }
            "annotations" => {
              "summary" => "发现错误日志"
              "description" => "%{log_message}"
            }
          }
        ]
      }
    }
  }
  
  # 备份输出到文件
  file {
    path => "/var/log/logstash/backup/dlmp-%{+YYYY.MM.dd}.log"
    codec => json_lines
  }
}